---
layout: post
title: "Day 11 - Studying code"
categories: [ til, python, SQL ]
---

# Day 11 ‚Äî Python & SQL

üìÖ 2026-01-16

Today is **Day 11 of my learning journey**.

This post is written mainly for myself, but it may also help other beginners.

---

# How pandas assigns data when creating a new column

## The key rule

When you assign a new column in pandas:

```python
df["AgeGroup"] = value
```

**pandas aligns data by index, not by row position.**

---

## What happens in different cases

### 1. Value has the same length as the DataFrame

```python
df["AgeGroup"] = pd.cut(df["Age"], bins=[0, 18, 65, 100])
```

- Length matches number of rows
- Index matches automatically
- Values are assigned row by row
  This is the **safe and common case**.

---

### 2. Value is a list/array with a different length

```python
df["AgeGroup"] = ["child", "adult"]
```

- pandas raises a `ValueError`
- It refuses to guess how to align the data

---

### 3. Value is a Series with its own index

```python
groups = pd.Series(["adult", "senior"], index=[1, 3])
df["AgeGroup"] = groups
```

- pandas aligns values by **index labels**
- Rows without a matching index get `NaN`

This can be surprising if you expect positional assignment.

---

### 4. Value is a single scalar

```python
df["AgeGroup"] = "unknown"
```

- The value is **broadcast** to all rows

---

## Why `pd.cut` works well

- `pd.cut(df["Age"])` returns a Series
- The Series keeps the same index as the original column
- This guarantees correct alignment when assigning

---

## Debug tip

If you see unexpected `NaN`s after assignment, check index alignment:

```python
df.index.equals(other.index)
```

# Creating pandas DataFrames (Python)

## Key idea

A pandas `DataFrame` does **NOT** require raw data to be dictionaries.
It can be created from multiple data structures, but the choice affects
how pandas interprets rows and columns.

---

## 1. List of dictionaries (row-oriented, safest)

```python
data = [
    {"date": "2025-01-01", "weight": 70.2, "fat": 15.3},
    {"date": "2025-02-01", "weight": 69.5, "fat": 14.7}
]

df = pd.DataFrame(data)
```

Each dictionary = one row
Dictionary keys = column names
Best when data is collected record-by-record (e.g. OCR results)

## 2. List of lists (row-oriented, positional)

data = [
["2025-01-01", 70.2, 15.3],
["2025-02-01", 69.5, 14.7]
]
df = pd.DataFrame(data, columns=["date", "weight", "fat"])
Each inner list = one row
Column meaning depends on position
Risky if order changes or columns are missing

## 3. Dictionary of lists (column-oriented, R-like)

data = {
"date": ["2025-01-01", "2025-02-01"],
"weight": [70.2, 69.5],
"fat": [15.3, 14.7]
}
df = pd.DataFrame(data)
Each key = column
Each list = column values
Good for time-series or calculated metrics

‚Äª For most real-world data pipelines (e.g. OCR ‚Üí parsing ‚Üí storage),
use a list of dictionaries for clarity and safety.

# `errors="coerce"` in `pd.to_datetime()`

## What it does

`errors="coerce"` tells pandas to:

- Convert valid dates normally
- Replace invalid or unparseable dates with `NaT`
- Avoid crashing the program
  `NaT` = ‚ÄúNot a Time‚Äù (datetime version of `NaN`)

---

## Comparison

| errors option       | Behavior                                 |
|---------------------|------------------------------------------|
| `"raise"` (default) | Stop execution on first error            |
| `"coerce"`          | Invalid dates ‚Üí `NaT`                    |
| `"ignore"`          | Leave values unchanged (not recommended) |

---

## Why it matters
Real-world data often contains:

- Mixed formats
- Typos
- Missing values
- OCR errors

`errors="coerce"` allows safe conversion and later cleanup.

---

## Common follow-up steps

```python
df["date"] = pd.to_datetime(df["date"], errors="coerce")
df = df.dropna(subset=["date"])
```